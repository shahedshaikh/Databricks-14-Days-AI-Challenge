{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fec3cba8-fd34-417d-a8f0-5f2a350769c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.spark\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression as SparkLogReg\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "648122ab-d395-4990-9a1f-df9c5fffed79",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "data = []\n",
    "\n",
    "for _ in range(500):\n",
    "    study_hours = round(random.uniform(0, 6), 1)\n",
    "    attendance = random.randint(50, 100)\n",
    "    previous_score = random.randint(30, 100)\n",
    "    assignments = random.randint(40, 100)\n",
    "\n",
    "    passed = (\n",
    "        study_hours > 2 and\n",
    "        attendance > 70 and\n",
    "        previous_score > 50 and\n",
    "        assignments > 60\n",
    "    )\n",
    "\n",
    "    data.append([\n",
    "        study_hours,\n",
    "        attendance,\n",
    "        previous_score,\n",
    "        assignments,\n",
    "        int(passed)\n",
    "    ])\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    data,\n",
    "    columns=[\n",
    "        \"study_hours\",\n",
    "        \"attendance_pct\",\n",
    "        \"previous_score\",\n",
    "        \"assignments_completed\",\n",
    "        \"pass\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "X = df.drop(\"pass\", axis=1)\n",
    "y = df[\"pass\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae21d608-da74-4bb4-a351-7f4bdcc67735",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.12/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n  warnings.warn(\nRegistered model 'student_pass_model' already exists. Creating a new version of this model...\nCreated version '1' of model 'workspace.default.student_pass_model'.\n/databricks/python/lib/python3.12/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n  warnings.warn(\nRegistered model 'student_pass_model' already exists. Creating a new version of this model...\nCreated version '2' of model 'workspace.default.student_pass_model'.\n/databricks/python/lib/python3.12/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n  warnings.warn(\nRegistered model 'student_pass_model' already exists. Creating a new version of this model...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83D\uDCCA Model Accuracies: {'LogisticRegression': 0.83, 'DecisionTree': 1.0, 'RandomForest': 1.0}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '3' of model 'workspace.default.student_pass_model'.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from mlflow.models.signature import infer_signature\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "models = {\n",
    "    \"LogisticRegression\": LogisticRegression(max_iter=1000),\n",
    "    \"DecisionTree\": DecisionTreeClassifier(max_depth=5),\n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "# Ensure no active MLflow run\n",
    "mlflow.end_run()\n",
    "\n",
    "for name, model in models.items():\n",
    "    with mlflow.start_run(run_name=name):\n",
    "        # Train\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict\n",
    "        preds = model.predict(X_test)\n",
    "        acc = accuracy_score(y_test, preds)\n",
    "\n",
    "        # \uD83D\uDD39 Infer model signature (REQUIRED for Unity Catalog)\n",
    "        signature = infer_signature(X_train, model.predict(X_train))\n",
    "\n",
    "        # Log params & metrics\n",
    "        mlflow.log_param(\"model_type\", name)\n",
    "        mlflow.log_metric(\"accuracy\", acc)\n",
    "\n",
    "        # Log + register model WITH signature\n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model=model,\n",
    "            artifact_path=name,\n",
    "            registered_model_name=\"student_pass_model\",\n",
    "            signature=signature\n",
    "        )\n",
    "\n",
    "        results[name] = acc\n",
    "\n",
    "print(\"\uD83D\uDCCA Model Accuracies:\", results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "030cfacd-893a-421c-abef-17ef5610afdf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "signature = infer_signature(\n",
    "    X_train.astype(\"float64\"),\n",
    "    model.predict(X_train).astype(\"int64\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21c132bd-2458-49db-9dc8-6f194b43a6d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83C\uDFC6 Best Sklearn Model: DecisionTree (1.0000)\n"
     ]
    }
   ],
   "source": [
    "best_model_name = max(results, key=results.get)\n",
    "best_accuracy = results[best_model_name]\n",
    "\n",
    "print(f\"\uD83C\uDFC6 Best Sklearn Model: {best_model_name} ({best_accuracy:.4f})\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Day13-Work",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}